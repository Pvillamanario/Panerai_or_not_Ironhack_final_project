{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# # Feature extraction and reverse image search"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.imagenet_utils import decode_predictions, preprocess_input\nfrom tensorflow.keras.models import Model\nfrom sklearn.decomposition import PCA\nfrom scipy.spatial import distance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Dowload VGG19 model\nmodel = tf.keras.applications.VGG19(weights='imagenet', include_top=True)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and prepare img\n\ndef load_image(path):\n    img = image.load_img(path, target_size=model.input_shape[1:3])\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return img, x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, x = load_image('../input/wf-panerai-feat-extc/WF_panerai/109645_PAM00332_Luminor Marina.jpeg')\nprint(\"data type: \", x.dtype)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the last layer (the classification layer), so that the final layer of the new network, called feat_extractor is the second 4096-neuron fully-connected layer,\"fc2 (Dense)\"\n\nfeat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"fc2\").output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.input_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the feature vector:\nimg, x = load_image('../input/wf-panerai-feat-extc/WF_panerai/109645_PAM00332_Luminor Marina.jpeg')\nfeat = feat_extractor.predict(x)\nplt.figure(figsize=(16,4))\nplt.plot(feat[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the directory from which images, the model will extract the feature vectors.\n# These are the waches on stock\n\nimages_path = '../input/wf-panerai-feat-extc/WF_panerai'\nimage_extensions = ['.jpg', '.png', '.jpeg']  \n\nimages = [os.path.join(dp, f) for dp, dn, filenames in os.walk(images_path) for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]\n\nprint(f'Keeping {len(images)} watches on stock to analyze.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting the feature vector from each image\n\nfeatures = []\n\nfor i, image_path in enumerate(images):\n    img, x = load_image(image_path);\n    feat = feat_extractor.predict(x)[0]\n    features.append(feat)\n\nprint(f'Finished extracting features for {len(images)} images.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(features).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# )PCA) to reduce the dimensionality of our feature vector. \n# We apply PCA for two reasons: \n# - The 4096-bit feature vector may have some redundancy in it. \n# - Operating over 4096 elements is inefficient both in terms of space/memory.\n\nfeatures = np.array(features)\npca = PCA(n_components=200)\npca.fit(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_features = pca.transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grab a random query image\nquery_image_idx = int(len(images) * random.random())\n\n# let's display the image\nimg = image.load_img(images[query_image_idx])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using cosine similarity to find similar feature vectors\nsimilar_idx = [ distance.cosine(pca_features[query_image_idx], feat) for feat in pca_features ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The list `similar_idx` contains the image's similarity to every other one. We can sort that list and find the indexes of the most similar images. \n# The next cell will sort them, and then find the most similar items, and return the indexes 5 most similar images. \n# We take from indexes 1:6 rather than 0:5 because the most similar image to the query image, will trivially be the query image itself, \n# since it is included in the distance calculation. So we just skip it.\n\nidx_closest = sorted(range(len(similar_idx)), key=lambda k: similar_idx[k])[1:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Opens the images specified by idx_closest and concatenates them into a single image (resizing each so it has a height of 100 pixels.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thumbs = []\nfor idx in idx_closest:\n    print(images[idx])\n    img = image.load_img(images[idx])\n    img = img.resize((int(img.width * 224 / img.height), 224))\n    thumbs.append(img)\n\n# concatenate the images into a single image\nconcat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n\n# show the image\nplt.figure(figsize = (16,12))\nplt.imshow(concat_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Refactoring \n\ndef get_closest_images(query_image_idx, num_results=5):\n    distances = [ distance.cosine(pca_features[query_image_idx], feat) for feat in pca_features ]\n    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:num_results+1]\n    return idx_closest\n\ndef get_concatenated_images(indexes, thumb_height):\n    thumbs = []\n    for idx in indexes:\n        img = image.load_img(images[idx])\n        img = img.resize((int(img.width * thumb_height / img.height), thumb_height))\n        thumbs.append(img)\n    concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n    return concat_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load image and extract features\nnew_image, x = load_image('../input/panerai-models/Panerai_Models/Ferrari/Ferrari_129.jpeg')\nnew_features = feat_extractor.predict(x)\n\n# project it into pca space\nnew_pca_features = pca.transform(new_features)[0]\n\n# calculate its distance to all the other images pca feature vectors\ndistances = [ distance.cosine(new_pca_features, feat) for feat in pca_features ]\nidx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[0:5]  # grab first 5\nresults_image = get_concatenated_images(idx_closest, 200)\n\n# display the results\nplt.figure(figsize = (5,5))\nplt.imshow(new_image)\nplt.title(\"query image\")\n\n# display the resulting images\nplt.figure(figsize = (16,12))\nplt.imshow(results_image)\nplt.title(\"result images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exporting model VGG19\nmodel.save('../models/VGG19_ft_ext.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}